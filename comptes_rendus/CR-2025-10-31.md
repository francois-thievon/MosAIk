# ğŸ—“ï¸ RÃ©union du 31 octobre

## ğŸ¯ Objectif principal
Montrer que la **quantification dâ€™incertitude pour la dÃ©tection dâ€™anomalies** est **plus performante avec des auto-encodeurs** quâ€™avec des classifieurs classiques.

## ğŸ“š TÃ¢ches et points Ã  approfondir
- Se **familiariser avec le papier â€œInformation Bottleneck Methodâ€**.  
  â†’ Faire un **rÃ©sumÃ© complet** du contenu de ce papier.  
- Se **renseigner sur le dataset MNIST**.  
- Noter que le **classifieur et lâ€™auto-encodeur doivent partager les mÃªmes premiÃ¨res couches de neurones**.

## âš™ï¸ Ã‰tapes prÃ©vues
1. **Mettre en place deux rÃ©seaux de neurones** sur MNIST :
   - Un **classifieur** : prÃ©dire le chiffre prÃ©sent dans lâ€™image.  
   - Un **auto-encodeur** : reconstruire le chiffre Ã  partir de son image dâ€™entrÃ©e.  
2. VÃ©rifier et comparer le **fonctionnement** des deux modÃ¨les.  
3. Pour lâ€™auto-encodeur : le **nombre de neurones en sortie doit correspondre au nombre dâ€™entrÃ©es** (et non Ã  deux neurones finaux).

## ğŸ—‚ï¸ Organisation
- **Renommer les dÃ©pÃ´ts** pour assurer une meilleure correspondance entre les projets.
