# DÃ©monstration : Application sur donnÃ©es rÃ©elles

## ğŸ¯ Objectif

Cette partie a pour but de **mettre en Ã©vidence la perte dâ€™information liÃ©e Ã  la modÃ©lisation de lâ€™incertitude** lorsque le modÃ¨le est contraint par une tÃ¢che de classification supervisÃ©e.

Ã€ travers des **jeux de donnÃ©es rÃ©els** comme **MNIST** ou **CIFAR-10**, nous comparons :
- un **rÃ©seau de classification** (ex. LeNet) entraÃ®nÃ© sur des Ã©tiquettes explicites,  
- un **auto-encodeur** visant uniquement Ã  reconstruire lâ€™entrÃ©e sans supervision.

## ğŸ§  Intention

Lâ€™objectif est de **visualiser concrÃ¨tement les diffÃ©rences dâ€™incertitude** :
- Comportement des distributions de probabilitÃ© de sortie,  
- QualitÃ© des reprÃ©sentations latentes,  
- SensibilitÃ© aux exemples ambigus ou hors distribution.

Ces expÃ©riences servent de **dÃ©monstration intuitive** de lâ€™hypothÃ¨se, avant toute validation statistique ou formelle.

## ğŸ§° UtilitÃ©

Cette partie fournit :
- Une **preuve qualitative** par observation visuelle,  
- Une base de **notebooks illustratifs** pour comprendre le phÃ©nomÃ¨ne,  
- Un point dâ€™entrÃ©e pour tester et visualiser les effets de la contrainte de classification.

---
