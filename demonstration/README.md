# D√©monstration : Application sur donn√©es r√©elles

## üéØ Objectif

Cette partie a pour but de **mettre en √©vidence la perte d'information li√©e √† la mod√©lisation de l'incertitude** lorsque le mod√®le est contraint par une t√¢che de classification supervis√©e.

√Ä travers des **jeux de donn√©es r√©els** comme **MNIST** ou **CIFAR-10**, nous comparons :
- un **r√©seau de classification** (ex. LeNet) entra√Æn√© sur des √©tiquettes explicites,  
- un **auto-encodeur** visant uniquement √† reconstruire l'entr√©e sans supervision.

## üß† Intention

L'objectif est de **visualiser concr√®tement les diff√©rences d'incertitude** :
- Comportement des distributions de probabilit√© de sortie,  
- Qualit√© des repr√©sentations latentes,  
- Sensibilit√© aux exemples ambigus ou hors distribution.

Ces exp√©riences servent de **d√©monstration intuitive** de l'hypoth√®se, avant toute validation statistique ou formelle.

## üß∞ Utilit√©

Cette partie fournit :
- Une **preuve qualitative** par observation visuelle,  
- Une base de **notebooks illustratifs** pour comprendre le ph√©nom√®ne,  
- Un point d'entr√©e pour tester et visualiser les effets de la contrainte de classification.

---

# üìì Notebook: `demo_mnist.ipynb`

## üìã Vue d'ensemble

Le notebook `demo_mnist.ipynb` d√©montre une **approche compl√®te de quantification d'incertitude** sur le dataset **MNIST**, en comparant deux architectures :
1. **Deep Ensemble de MLPs** (r√©seaux de classification supervis√©e)
2. **Deep Ensemble d'Autoencodeurs** (r√©seaux de reconstruction non-supervis√©e)

---

## üìö Organisation g√©n√©rale du notebook

Le notebook suit cette structure :
Cellules 1-6 ‚Üí Chargement et visualisation MNIST
Cellules 7-10 ‚Üí Baseline MLP (784‚Üí256‚Üí128‚Üí10)
Cellules 11-13 ‚Üí Single Autoencoder (784‚Üí256‚Üí128‚Üí10‚Üí128‚Üí256‚Üí784)
Cellules 14-15 ‚Üí Chargement Fashion MNIST (donn√©es OOD)
Cellules 16-22 ‚Üí Deep Ensemble MLP (K=10) + Uncertainties
Cellules 23-28 ‚Üí Deep Ensemble Autoencodeurs (K=10) + Uncertainties
Cellule 29 ‚Üí Comparaison MLP vs Autoencodeurs

---

## üîç D√©tails par section

### Section 1-4 : Donn√©es et Baseline

**MNIST Loading** - Chargement du dataset complet (60K train, 10K test) via fichiers IDX binaires

**MLP Baseline** - R√©seau simple 784‚Üí256‚Üí128‚Üí10 pour r√©f√©rence de performance (~97% accuracy)

**Single Autoencoder** - Autoencodeur de d√©monstration avec bottleneck 10D pour v√©rifier la reconstruction

**Fashion MNIST** - 1,000 images de Fashion MNIST comme donn√©es hors-distribution (OOD test set)

---

### Section 5 : Deep Ensemble MLP - Quantification d'incertitude

#### Architecture
- **K=10 mod√®les MLP** entra√Æn√©s avec bootstrap sampling
- Chaque mod√®le re√ßoit un √©chantillon al√©atoire (60K avec remise) ‚Üí ~38K uniques
- Seeds diff√©rentes pour diversit√©

#### Calcul d'incertitude

**Aleatoric Uncertainty** (incertitude des donn√©es)

$$u_a = H(\bar{p}(x)) = -\sum_{i=0}^{9} \bar{p}_i(x) \log(\bar{p}_i(x))$$

o√π $\bar{p}(x) = \frac{1}{K}\sum_{k=1}^{K} p_k(x)$

**Epistemic Uncertainty** (incertitude du mod√®le via Mutual Information)

$$u_e = MI = H(\bar{p}(x)) - \frac{1}{K}\sum_{k=1}^{K} H(p_k(x))$$

#### D√©tection OOD

**Seuil** : 75e percentile du ratio $u_e / u_a$ sur MNIST

**D√©cision** : 
- Si ratio > threshold ‚Üí Class√© comme **OOD (anomaly)**
- Sinon ‚Üí Class√© comme **ID (normal)**

**R√©sultats attendus** :
- **FPR** (MNIST) : ~25% (faux positifs acceptables)
- **TPR** (Fashion MNIST) : ~90%+ (excellente d√©tection)

#### Visualisations

1. **KDE Plot Aleatoric** : Distributions MNIST vs Fashion MNIST (quasi-identiques = attendu)
2. **KDE Plot Epistemic** : Distributions bien s√©par√©es (MNIST << Fashion MNIST)
3. **2D Scatter** : Aleatoric vs Epistemic avec limite d√©cisionnelle (diagonal)

---

### Section 6 : Deep Ensemble Autoencodeurs - Quantification d'incertitude

#### Diff√©rence cl√©

Les **MLPs** pr√©disent directement $p_k(x)$ ‚àà ‚Ñù^10 via softmax du dernier layer.

Les **Autoencodeurs** utilisent la **couche bottleneck** (10 neurones ReLU) comme base de pr√©diction :
- Forward pass jusqu'√† bottleneck : $z_k(x)$ ‚àà ‚Ñù^10
- Conversion en probabilit√©s : $p_k(x) = \text{softmax}(z_k(x))$
- Justification : Repr√©sentation **non-supervis√©e**, pas biais√©e par les labels

#### Architecture
784 ‚Üí [256 ReLU] ‚Üí [128 ReLU] ‚Üí [10 ReLU bottleneck] ‚Üí [128 ReLU] ‚Üí [256 ReLU] ‚Üí [784 Sigmoid]
Encoder Decoder


#### Entra√Ænement

- **K=10 autoencodeurs** avec bootstrap sampling (identique aux MLPs)
- Loss : **MSE reconstruction**
- Bottleneck extraction apr√®s entra√Ænement

#### Calcul d'incertitude (identique aux MLPs)

$$u_a = H(\bar{p}(x))$$

$$u_e = MI = H(\bar{p}(x)) - \frac{1}{K}\sum_{k=1}^{K} H(p_k(x))$$

#### OOD Detection (identique aux MLPs)

M√™me strat√©gie ratio-based, seuil ind√©pendant calcul√© sur MNIST

---

### Section 7 : Comparaison MLP vs Autoencodeurs

**M√©triques compar√©es :**

| Aspect | MLP | Autoencodeur |
|--------|-----|--------------|
| Architecture | Supervis√©e | Non-supervis√©e |
| Pr√©dictions | Softmax direct | Bottleneck softmax |
| FPR (MNIST) | ~25% | ? |
| TPR (Fashion) | ~90%+ | ? |
| Repr√©sentation | 128D ‚Üí 10D softmax | 10D ReLU bottleneck |

**Questions explor√©es :**
- Quelle approche a meilleure s√©paration ID/OOD?
- L'absence de labels aide-t-elle ou nuit-elle?
- Les repr√©sentations autoencodeur sont-elles plus robustes?

---

## üöÄ Utilisation

```bash
cd demonstration/
jupyter notebook demo_mnist.ipynb
```
temps estim√© : 1h